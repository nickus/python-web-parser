#!/usr/bin/env python3
"""
Performance Testing Script –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Elasticsearch —Å–µ—Ä–≤–∏—Å–∞
–ê–≤—Ç–æ—Ä: Claude Code Assistant
–í–µ—Ä—Å–∏—è: 1.0

–î–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Elasticsearch —Å–µ—Ä–≤–∏—Å–∞
–∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –≤—Å–µ—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π.
"""

import sys
import time
import json
import logging
from datetime import datetime
from typing import Dict, Any, List

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('performance_test.log')
    ]
)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
from src.services.elasticsearch_service import ElasticsearchService
from src.models.material import Material, PriceListItem


class PerformanceTestSuite:
    """–ù–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Elasticsearch"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞"""
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        self.es_service = ElasticsearchService(
            host='localhost',
            port=9200,
            bulk_size=1000,  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π bulk_size
            max_workers=6    # –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
        )
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.test_materials = self._generate_test_materials()
        self.test_price_items = self._generate_test_price_items()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
        self.test_results = {}
        
        logger.info("Performance Test Suite initialized")
        logger.info(f"Elasticsearch service configured: bulk_size={self.es_service.bulk_size}, max_workers={self.es_service.max_workers}")
    
    def _generate_test_materials(self) -> List[Material]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
        materials = []
        
        # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        test_data = [
            {"name": "–ö–∞–±–µ–ª—å –í–í–ì–Ω–≥-LS 3x2.5", "category": "–ö–∞–±–µ–ª–∏", "brand": "ElectroMax", "description": "–ú–µ–¥–Ω—ã–π —Å–∏–ª–æ–≤–æ–π –∫–∞–±–µ–ª—å"},
            {"name": "–í—ã–∫–ª—é—á–∞—Ç–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π C16", "category": "–ê–≤—Ç–æ–º–∞—Ç–∏–∫–∞", "brand": "Schneider", "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–∫–ª—é—á–∞—Ç–µ–ª—å 16–ê"},
            {"name": "–õ–∞–º–ø–∞ LED 10W E27", "category": "–û—Å–≤–µ—â–µ–Ω–∏–µ", "brand": "Philips", "description": "–°–≤–µ—Ç–æ–¥–∏–æ–¥–Ω–∞—è –ª–∞–º–ø–∞ 10 –≤–∞—Ç—Ç"},
            {"name": "–ü—Ä–æ–≤–æ–¥ –ü–í–° 2x1.5", "category": "–ü—Ä–æ–≤–æ–¥–∞", "brand": "Rexant", "description": "–ì–∏–±–∫–∏–π —Å–æ–µ–¥–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≤–æ–¥"},
            {"name": "–†–æ–∑–µ—Ç–∫–∞ —Å –∑–∞–∑–µ–º–ª–µ–Ω–∏–µ–º", "category": "–†–æ–∑–µ—Ç–∫–∏", "brand": "Legrand", "description": "–†–æ–∑–µ—Ç–∫–∞ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ç–∏–ø–∞"},
        ]
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ 20 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        for i, base_data in enumerate(test_data):
            for j in range(20):
                material = Material(
                    id=f"mat_{i}_{j}",
                    name=f"{base_data['name']} - –≤–∞—Ä–∏–∞–Ω—Ç {j+1}",
                    description=f"{base_data['description']} (—Ç–µ—Å—Ç {j+1})",
                    category=base_data['category'],
                    brand=base_data['brand'],
                    specifications={
                        "test_param": f"value_{j}",
                        "batch": f"batch_{i}_{j}"
                    }
                )
                materials.append(material)
        
        logger.info(f"Generated {len(materials)} test materials")
        return materials
    
    def _generate_test_price_items(self) -> List[PriceListItem]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞"""
        price_items = []
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞
        test_data = [
            {"name": "–ö–∞–±–µ–ª—å —Å–∏–ª–æ–≤–æ–π –º–µ–¥–Ω—ã–π", "supplier": "–≠–ª–µ–∫—Ç—Ä–æ–¢–æ—Ä–≥", "price": 125.50},
            {"name": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–∫–ª—é—á–∞—Ç–µ–ª—å", "supplier": "–¢–µ—Ö–Ω–æ–û–ø—Ç", "price": 890.00},
            {"name": "–°–≤–µ—Ç–æ–¥–∏–æ–¥–Ω–∞—è –ª–∞–º–ø–∞", "supplier": "–°–≤–µ—Ç–¢–µ—Ö", "price": 350.75},
            {"name": "–ì–∏–±–∫–∏–π –ø—Ä–æ–≤–æ–¥ —Å–æ–µ–¥–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π", "supplier": "–ö–∞–±–µ–ª—å–°–Ω–∞–±", "price": 45.20},
            {"name": "–†–æ–∑–µ—Ç–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è", "supplier": "–≠–ª–µ–∫—Ç—Ä–æ–ö–æ–º–ø–ª–µ–∫—Ç", "price": 280.30},
        ]
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ 15 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞
        for i, base_data in enumerate(test_data):
            for j in range(15):
                price_item = PriceListItem(
                    id=f"price_{i}_{j}",
                    material_name=f"{base_data['name']} –º–æ–¥–µ–ª—å {j+1}",
                    price=base_data['price'] + (j * 10),
                    currency="RUB",
                    supplier=base_data['supplier'],
                    description=f"–¢–µ—Å—Ç–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ {j+1}"
                )
                price_items.append(price_item)
        
        logger.info(f"Generated {len(price_items)} test price items")
        return price_items
    
    def test_connection(self) -> bool:
        """–¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Elasticsearch"""
        logger.info("=== TEST 1: Connection Test ===")
        
        start_time = time.time()
        connection_ok = self.es_service.check_connection()
        duration = time.time() - start_time
        
        self.test_results['connection'] = {
            'status': 'PASS' if connection_ok else 'FAIL',
            'duration_ms': round(duration * 1000, 2),
            'details': 'Elasticsearch connection successful' if connection_ok else 'Connection failed'
        }
        
        logger.info(f"Connection test: {'PASS' if connection_ok else 'FAIL'} ({duration:.3f}s)")
        return connection_ok
    
    def test_index_creation(self) -> bool:
        """–¢–µ—Å—Ç 2: –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤"""
        logger.info("=== TEST 2: Optimized Index Creation ===")
        
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        materials_ok = self.es_service.create_materials_index()
        price_list_ok = self.es_service.create_price_list_index()
        
        duration = time.time() - start_time
        
        success = materials_ok and price_list_ok
        self.test_results['index_creation'] = {
            'status': 'PASS' if success else 'FAIL',
            'duration_ms': round(duration * 1000, 2),
            'materials_index': materials_ok,
            'price_list_index': price_list_ok,
            'details': 'Optimized indices created with Russian analyzer and performance settings'
        }
        
        logger.info(f"Index creation test: {'PASS' if success else 'FAIL'} ({duration:.3f}s)")
        return success
    
    def test_bulk_indexing_performance(self) -> bool:
        """–¢–µ—Å—Ç 3: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–∞—Å—Å–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        logger.info("=== TEST 3: Bulk Indexing Performance ===")
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª—ã
        start_time = time.time()
        materials_success = self.es_service.index_materials(self.test_materials)
        materials_duration = time.time() - start_time
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø—Ä–∞–π—Å-–ª–∏—Å—Ç
        start_time = time.time()
        price_success = self.es_service.index_price_list(self.test_price_items)
        price_duration = time.time() - start_time
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        materials_per_sec = len(self.test_materials) / materials_duration if materials_duration > 0 else 0
        price_per_sec = len(self.test_price_items) / price_duration if price_duration > 0 else 0
        
        success = materials_success and price_success
        self.test_results['bulk_indexing'] = {
            'status': 'PASS' if success else 'FAIL',
            'materials': {
                'count': len(self.test_materials),
                'duration_s': round(materials_duration, 3),
                'docs_per_sec': round(materials_per_sec, 1),
                'success': materials_success
            },
            'price_list': {
                'count': len(self.test_price_items),
                'duration_s': round(price_duration, 3),
                'docs_per_sec': round(price_per_sec, 1),
                'success': price_success
            }
        }
        
        logger.info(f"Bulk indexing test: {'PASS' if success else 'FAIL'}")
        logger.info(f"  Materials: {materials_per_sec:.1f} docs/sec")
        logger.info(f"  Price list: {price_per_sec:.1f} docs/sec")
        return success
    
    def test_search_performance(self) -> bool:
        """–¢–µ—Å—Ç 4: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞"""
        logger.info("=== TEST 4: Search Performance ===")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_queries = [
            "–∫–∞–±–µ–ª—å",
            "–∞–≤—Ç–æ–º–∞—Ç",
            "–ª–∞–º–ø–∞ led",
            "–ø—Ä–æ–≤–æ–¥ –ø–≤—Å",
            "—Ä–æ–∑–µ—Ç–∫–∞ –∑–∞–∑–µ–º–ª–µ–Ω–∏–µ"
        ]
        
        search_results = []
        
        for query in test_queries:
            # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
            start_time = time.time()
            materials = self.es_service.search_materials(query, 10)
            materials_duration = time.time() - start_time
            
            # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫
            start_time = time.time()
            materials_cached = self.es_service.search_materials_cached(query, 10)
            cached_duration = time.time() - start_time
            
            # –ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–µ
            start_time = time.time()
            price_items = self.es_service.search_price_list_cached(query, 20)
            price_duration = time.time() - start_time
            
            search_results.append({
                'query': query,
                'materials_count': len(materials),
                'materials_duration_ms': round(materials_duration * 1000, 2),
                'cached_duration_ms': round(cached_duration * 1000, 2),
                'price_items_count': len(price_items),
                'price_duration_ms': round(price_duration * 1000, 2)
            })
        
        # –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        avg_materials_time = sum(r['materials_duration_ms'] for r in search_results) / len(search_results)
        avg_cached_time = sum(r['cached_duration_ms'] for r in search_results) / len(search_results)
        
        success = all(r['materials_count'] >= 0 for r in search_results)
        self.test_results['search_performance'] = {
            'status': 'PASS' if success else 'FAIL',
            'queries_tested': len(test_queries),
            'avg_materials_search_ms': round(avg_materials_time, 2),
            'avg_cached_search_ms': round(avg_cached_time, 2),
            'cache_speedup_factor': round(avg_materials_time / max(avg_cached_time, 0.001), 1),
            'detailed_results': search_results
        }
        
        logger.info(f"Search performance test: {'PASS' if success else 'FAIL'}")
        logger.info(f"  Average search time: {avg_materials_time:.2f}ms")
        logger.info(f"  Average cached time: {avg_cached_time:.2f}ms")
        return success
    
    def test_caching_system(self) -> bool:
        """–¢–µ—Å—Ç 5: –°–∏—Å—Ç–µ–º–∞ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info("=== TEST 5: Caching System ===")
        
        # –û—á–∏—â–∞–µ–º –∫–µ—à
        self.es_service.clear_cache()
        
        test_query = "—Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫–∞–±–µ–ª—å"
        
        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å (–¥–æ–ª–∂–µ–Ω –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∫–µ—à)
        start_time = time.time()
        results1 = self.es_service.search_materials_cached(test_query, 5)
        first_duration = time.time() - start_time
        
        # –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å (–¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à)
        start_time = time.time()
        results2 = self.es_service.search_materials_cached(test_query, 5)
        cached_duration = time.time() - start_time
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        search_report = self.es_service.get_search_performance_report()
        
        # –ö–µ—à –¥–æ–ª–∂–µ–Ω —Å—Ä–∞–±–æ—Ç–∞—Ç—å
        cache_hit = cached_duration < first_duration
        results_identical = len(results1) == len(results2)
        
        success = cache_hit and results_identical and search_report['cache_hits'] > 0
        self.test_results['caching_system'] = {
            'status': 'PASS' if success else 'FAIL',
            'first_query_ms': round(first_duration * 1000, 2),
            'cached_query_ms': round(cached_duration * 1000, 2),
            'speedup_factor': round(first_duration / max(cached_duration, 0.001), 1),
            'cache_hits': search_report['cache_hits'],
            'total_queries': search_report['total_queries'],
            'cache_hit_ratio': round(search_report['cache_hit_ratio'], 1)
        }
        
        logger.info(f"Caching system test: {'PASS' if success else 'FAIL'}")
        logger.info(f"  Cache speedup: {success and cache_hit}")
        logger.info(f"  Cache hit ratio: {search_report['cache_hit_ratio']:.1f}%")
        return success
    
    def test_production_optimization(self) -> bool:
        """–¢–µ—Å—Ç 6: –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        logger.info("=== TEST 6: Production Optimizations ===")
        
        start_time = time.time()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        optimization_success = self.es_service.optimize_for_production()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        index_stats = self.es_service.get_index_stats()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
        health = self.es_service.health_check()
        
        duration = time.time() - start_time
        
        success = optimization_success and health.get('connection_healthy', False)
        self.test_results['production_optimization'] = {
            'status': 'PASS' if success else 'FAIL',
            'duration_s': round(duration, 3),
            'optimization_success': optimization_success,
            'cluster_healthy': health.get('connection_healthy', False),
            'cluster_status': health.get('cluster_status', 'unknown'),
            'index_statistics': index_stats
        }
        
        logger.info(f"Production optimization test: {'PASS' if success else 'FAIL'}")
        logger.info(f"  Cluster status: {health.get('cluster_status', 'unknown')}")
        return success
    
    def test_monitoring_capabilities(self) -> bool:
        """–¢–µ—Å—Ç 7: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        logger.info("=== TEST 7: Monitoring Capabilities ===")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        performance_stats = self.es_service.get_performance_stats()
        search_stats = self.es_service.get_search_performance_report()
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        full_stats = self.es_service.export_performance_stats()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        required_keys = ['total_indexed_documents', 'average_documents_per_second', 'bulk_operations_count']
        stats_complete = all(key in performance_stats for key in required_keys)
        
        search_keys = ['total_queries', 'cache_hits', 'cache_hit_ratio']
        search_stats_complete = all(key in search_stats for key in search_keys)
        
        success = stats_complete and search_stats_complete and bool(full_stats)
        self.test_results['monitoring'] = {
            'status': 'PASS' if success else 'FAIL',
            'performance_stats_complete': stats_complete,
            'search_stats_complete': search_stats_complete,
            'export_successful': bool(full_stats),
            'total_indexed_docs': performance_stats.get('total_indexed_documents', 0),
            'avg_docs_per_sec': performance_stats.get('average_documents_per_second', 0),
            'total_queries': search_stats.get('total_queries', 0),
            'cache_hit_ratio': search_stats.get('cache_hit_ratio', 0)
        }
        
        logger.info(f"Monitoring capabilities test: {'PASS' if success else 'FAIL'}")
        logger.info(f"  Performance tracking: {stats_complete}")
        logger.info(f"  Search monitoring: {search_stats_complete}")
        return success
    
    def run_all_tests(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üöÄ Starting comprehensive performance test suite...")
        logger.info("=" * 60)
        
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
        tests = [
            ('connection', self.test_connection),
            ('index_creation', self.test_index_creation),
            ('bulk_indexing', self.test_bulk_indexing_performance),
            ('search_performance', self.test_search_performance),
            ('caching_system', self.test_caching_system),
            ('production_optimization', self.test_production_optimization),
            ('monitoring', self.test_monitoring_capabilities)
        ]
        
        passed_tests = 0
        failed_tests = 0
        
        for test_name, test_func in tests:
            try:
                success = test_func()
                if success:
                    passed_tests += 1
                else:
                    failed_tests += 1
            except Exception as e:
                logger.error(f"Test {test_name} failed with exception: {e}")
                self.test_results[test_name] = {
                    'status': 'ERROR',
                    'error': str(e)
                }
                failed_tests += 1
        
        total_duration = time.time() - start_time
        
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        final_report = {
            'test_suite': 'Elasticsearch Performance Optimization',
            'timestamp': datetime.now().isoformat(),
            'total_duration_s': round(total_duration, 3),
            'tests_passed': passed_tests,
            'tests_failed': failed_tests,
            'total_tests': len(tests),
            'success_rate': round((passed_tests / len(tests)) * 100, 1),
            'elasticsearch_config': {
                'host': self.es_service.host,
                'port': self.es_service.port,
                'bulk_size': self.es_service.bulk_size,
                'max_workers': self.es_service.max_workers
            },
            'detailed_results': self.test_results
        }
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.info("=" * 60)
        logger.info(f"üéØ TEST SUITE COMPLETED")
        logger.info(f"Total duration: {total_duration:.3f}s")
        logger.info(f"Tests passed: {passed_tests}/{len(tests)} ({final_report['success_rate']:.1f}%)")
        logger.info(f"Tests failed: {failed_tests}")
        
        if failed_tests == 0:
            logger.info("‚úÖ All performance optimizations working correctly!")
        else:
            logger.warning(f"‚ö†Ô∏è  {failed_tests} test(s) failed - check detailed results")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_filename = f"performance_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìÑ Full report saved to: {report_filename}")
        
        return final_report


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
    print("Elasticsearch Performance Optimization Test Suite")
    print("=" * 50)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
        test_suite = PerformanceTestSuite()
        results = test_suite.run_all_tests()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        if results['tests_failed'] == 0:
            print("\n‚úÖ All tests passed! Performance optimizations are working correctly.")
            return 0
        else:
            print(f"\n‚ùå {results['tests_failed']} test(s) failed. Check the logs for details.")
            return 1
            
    except Exception as e:
        logger.error(f"Test suite failed with critical error: {e}")
        print(f"\nüí• Test suite crashed: {e}")
        return 2


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)